

# 概述

OpenPCDet是MMLab的一个计算机视觉项目（当然不是传统的二维计算机视觉），一个开源的点云检测工具箱（或者说三维计算机视觉），它是由香港中文大学多媒体实验室（MMLab）开发的。此项目的主要目的是提供一个开源和统一的代码库，来帮助研究人员和开发人员更好地进行基于点云的物体检测研究。

OpenPCDet支持多种流行的3D物体检测算法，如PointPillars, SECOND, Part-A^2等。它提供了一个灵活的代码框架，可以很方便的进行各种点云检测算法的训练和测试。并且，OpenPCDet还提供了很多预训练的模型，可以方便的进行迁移学习。

OpenPCDet的代码框架主要由以下部分组成：

1. `pcdet/models`: 这个目录包含了所有支持的点云检测模型的代码，每个模型都有一个对应的python文件，例如`pointpillars.py`。
2. `pcdet/datasets`: 这个目录包含了数据集的处理代码，包括数据读取、预处理和后处理等。支持KITTI, Waymo, nuScenes等多种数据集。
3. `pcdet/utils`: 这个目录包含了一些工具函数，例如点云操作、计算IoU等。
4. `tools`: 这个目录包含了训练和测试模型的主要脚本。
5. `configs`: 这个目录包含了各种模型的配置文件，可以在这里修改模型参数、训练参数等。
6. `data`：这个目录是用来存放各种数据集的，经典的有KITTI、Waymo等数据集
7. `docs`：包含一些文档和效果展示图

接下来我们尝试自顶向下的方式去解析这个框架的运行原理（就是有哪些模块，这些模块之间怎么搭配的，每个模块有什么功能，然后去研究每个模块怎么做的），然后去了解底层模型的搭建过程

## Tools

模型是封装好的，然后通过tools文件夹下的代码进行启动和运行，我们先查看这里的代码如何构建的

我们首先看一下文件的结构，我们先忽略其具体有哪些文件

```shell
.
├── cfgs
│   ├── dataset_configs
│   ├── kitti_models
│   ├── nuscenes_models
│   └── waymo_models
├── demo.py
├── eval_utils
│   └── eval_utils.py
├── test.py
├── train.py
├── train_utils
│   ├── optimization
│   │   ├── fastai_optim.py
│   │   ├── __init__.py
│   │   └── learning_schedules_fastai.py
│   └── train_utils.py
└── visual_utils
    └── visualize_utils.py
```

### cfgs

这个文件夹中是数据集的配置文件，具体的配置方式数据以yaml文件的格式给出，这些配置文件用于设置模型的各种参数，包括但不限于模型结构、训练策略、数据集路径等

当你要训练或测试一个模型时，你需要指定一个配置文件，OpenPCDet会根据配置文件中的设置来构建模型、读取数据以及设置训练策略。

配置文件使得你可以在不修改代码的情况下，调整模型的各种设置，使得实验更加灵活和方便。

### utils

通常都是用于提供一些实用函数或类的。具体来说：

1. `eval_utils`: 这个文件夹主要包含了一些用于评估模型性能的实用工具。例如，它可能包含了计算各种度量（如精度、召回率、mAP等）的函数，以及将评估结果可视化或保存的函数。对于点云检测任务，这可能还包括一些特定的评估工具，例如用于计算3D物体检测的IoU（Intersection over Union）的函数。
2. `train_utils`: 这个文件夹主要包含了一些用于训练模型的实用工具。例如，它可能包含了设置优化器、学习率调度器的函数，或者用于在训练过程中保存模型、记录训练日志的函数。
3. `test_utils`: 这个文件夹主要包含了一些用于测试模型的实用工具。例如，它可能包含了加载模型、处理输入数据、解析模型输出的函数，以及将测试结果可视化或保存的函数。

这些`utils`文件夹为OpenPCDet的训练、测试和评估流程提供了一些基础的实用工具，使得这些过程更加模块化和灵活。

### Python文件

这些文件相当于开关，可以一键启动整个项目，完成训练、验证等操作

# 功能模块详解

## 总开关——train.py等

这是一个一键启动的开关，包括test.py和train.py，我们先分析其中的功能

这个代码有三部分，第一部分是一系列的模块导入，第二部分是从命令行读取参数的函数，第三部分是综合配置的主函数，用来处理参数并且运行模型

### 参数配置

在`parse_config`函数中，使用argparse模块读取命令行参数

```python
# 1.创建解释器
parser = argparse.ArgumentParser(description="Train a detector")
#description参数可写可不写，只是在命令行参数出现错误的时候，随着错误信息打印出来。
parser.add_argument("config", help="train config file path")
#参数的帮助信息
#其中，"config"和"cfg_file"这些都是参数名，不过前面带有"--"的表示是可选的参数，"config"这种是必选参数
parser.add_argument('--cfg_file', type=str, default=None, help='specify the config for training')
#type参数表示命令行参数应该被转换成的类型
#default参数表示默认值，不指定参数时，该参数会设置为默认值
parser.add_argument('--launcher', choices=['none', 'pytorch', 'slurm'], default='none')
#choices表示参数选择的容器，只能在这个范围内选择
```

### 主函数

`main()`是主函数，或者说是主训练函数，所有的模块在这里被集中调用，然后运行此函数就可以根据配置文件和参数去运行

1. 判断是否多GPU训练
2. 判断批量大小

# 工程总结

## 总体框架

不同的项目，在项目主目录下，会分为若干文件夹，如下

- `config`：各种配置文件
- 模型文件夹：包含了各种所需的模型
- `docs`：各种文档和说明
- `tools`：工具程序，同时也是集成各个模块的程序文件所在（比如说train.py文件）
- `data`：存放各种数据集文件

这样处理的好处就是非常独立

## 代码集成

其中，代码往往集成在tools文件夹下的train.py文件中，这个文件的作用相当于总闸门总开关

在train.py文件中，程序大致分为三部分，一部分是开头导包，导入依赖，一部分是解析命令行参数的函数，可以让人在输入命令行的时候就可以给参数，一部分是主函数文件，用来运行整个项目

其中，导包的地方，有一个需要注意的是`_init_path`这个模块，这个文件在同级目录下，作用是添加路径，便于调用

然后就是解析命令行参数的函数，这个函数一般命名为`parse_args()`，负责解析命令行中所附带的各种参数

其次是主函数`main()`，其中是调用各种模块，构建项目运行的主逻辑，主逻辑也就是判断是否分布式训练、启动器、调用各种API（包括使用命令行参数去构建数据集和模型）等

总的来说，代码非常集成，不存在涉及底层的代码，都是各种封装，有的甚至调用的是封装多层的API，将输入的参数转为用到的对象

## 主逻辑

主逻辑只不过内容较多，没有特别深入，都是调用各种模块，实现一些功能

1. 检测是否需要分布式训练，如果需要，则设置批量大小等参数
2. 准备日志输出所需要的代码，包括日志路径等数据
3. 根据参数构建Dataset和Dataloader，以及网络模型和优化器
4. 检查是否导入预训练的模型

# 数据集代码

数据集的数据，放在主目录下的`data`文件夹中，包括了点云中常用的数据集如KITTI、nuScenes等

数据集的代码，存放在主目录下的pcdet文件夹中的datasets子文件夹中，数据集方面代码的思想是两次封装，第一次是在子文件夹下构建dataset.py文件，构建一个直接继承Dataset类的模板类，在这里类名为`DatasetTemplate`，完成了一些点云数据集对象所必备的函数和功能，或者说这个类是所有数据集类的基类，提供了一些通用的方法和属性